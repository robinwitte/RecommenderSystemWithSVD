{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender system:\n",
    "## A collaborative filtering algorithm based on non-negative matrix factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import (absolute_import, division, print_function,\n",
    "                        unicode_literals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialization values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svd values\n",
    "n_factors     = 150\n",
    "n_epochs      = 20\n",
    "init_mean     = 0\n",
    "init_std_dev  = .1\n",
    "lr            = .005\n",
    "reg           = .001\n",
    "verbose       = False\n",
    "\n",
    "# crossvalidation\n",
    "n_splits      = 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import user-item-rating set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Reader, Dataset\n",
    "\n",
    "reader = Reader(line_format='user item rating', sep=',')\n",
    "\n",
    "data = Dataset.load_from_file('data/train.csv', reader=reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the cythonmagic extension (for cython code use the magic function %%cython):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVD class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "cimport numpy as np\n",
    "import numpy as np\n",
    "\n",
    "class SVD:\n",
    "        \n",
    "    \"\"\"A collaborative filtering algorithm based on Non-negative Matrix\n",
    "    Factorization. Adapted from Surprise\n",
    "    \n",
    "    Args:\n",
    "        n_factors: The number of factors. \n",
    "            Default is ``100``.\n",
    "        n_epochs: The number of iteration of the SGD procedure. \n",
    "            Default is ``20``.\n",
    "        reg: The regularization term :math:`\\gamma`. \n",
    "            Default is ``0.06``.\n",
    "        lr: The learning rate :math:`\\lambda`.\n",
    "            Default is ``0.005``.\n",
    "        verbose: If ``True``, prints the current epoch. Default is ``False``.\n",
    "        \n",
    "    Attributes:\n",
    "        pu(numpy array of size (n_users, n_factors)): The user factors (only\n",
    "            exists if ``fit()`` has been called)\n",
    "        qi(numpy array of size (n_items, n_factors)): The item factors (only\n",
    "            exists if ``fit()`` has been called)\n",
    "        bu(numpy array of size (n_users)): The user biases (only\n",
    "            exists if ``fit()`` has been called)\n",
    "        bi(numpy array of size (n_items)): The item biases (only\n",
    "            exists if ``fit()`` has been called)\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    def __init__(self, n_factors=100, n_epochs=20, init_mean=0,\n",
    "                 init_std_dev=.1, lr=.005, reg=.06, verbose=False):\n",
    "\n",
    "        self.n_factors = n_factors\n",
    "        self.n_epochs = n_epochs\n",
    "        self.init_mean = init_mean\n",
    "        self.init_std_dev = init_std_dev\n",
    "        self.lr = lr\n",
    "        self.reg = reg\n",
    "        self.verbose = verbose\n",
    "        \n",
    "    def fit(self, trainset):\n",
    "\n",
    "        self.sgd(trainset)\n",
    "\n",
    "        return self\n",
    "        \n",
    "    def sgd(self, trainset):\n",
    "\n",
    "        # user biases\n",
    "        cdef np.ndarray[np.double_t] bu\n",
    "        # item biases\n",
    "        cdef np.ndarray[np.double_t] bi\n",
    "        # user factors\n",
    "        cdef np.ndarray[np.double_t, ndim=2] pu\n",
    "        # item factors\n",
    "        cdef np.ndarray[np.double_t, ndim=2] qi\n",
    "        \n",
    "        \n",
    "        cdef double global_mean = trainset.global_mean\n",
    "        cdef double lr = self.lr\n",
    "        cdef double reg = self.reg\n",
    "        \n",
    "        cdef int u, i, f\n",
    "        cdef double r, err, dot, puf, qif\n",
    "        \n",
    "        pu = np.random.normal(self.init_mean, self.init_std_dev,\n",
    "                              (trainset.n_users, self.n_factors))\n",
    "        qi = np.random.normal(self.init_mean, self.init_std_dev,\n",
    "                              (trainset.n_users, self.n_factors))\n",
    "        bu = np.zeros(trainset.n_users, np.double)\n",
    "        bi = np.zeros(trainset.n_items, np.double)\n",
    "\n",
    "        \n",
    "        for current_epoch in range(self.n_epochs):\n",
    "            if self.verbose:\n",
    "                print(\"Processing epoch {}\".format(current_epoch))\n",
    "            for u, i, r in trainset.all_ratings():\n",
    "\n",
    "                # compute current error\n",
    "                dot = 0  # <q_i, p_u>\n",
    "                for f in range(self.n_factors):\n",
    "                    dot += qi[i, f] * pu[u, f]\n",
    "                err = r - (global_mean + bu[u] + bi[i] + dot)\n",
    "\n",
    "                # update biases\n",
    "                bu[u] += lr * (err - reg * bu[u])\n",
    "                bi[i] += lr * (err - reg * bi[i])\n",
    "\n",
    "                # update factors\n",
    "                for f in range(self.n_factors):\n",
    "                    puf = pu[u, f]\n",
    "                    qif = qi[i, f]\n",
    "                    pu[u, f] += lr * (err * qif - reg * puf)\n",
    "                    qi[i, f] += lr * (err * puf - reg * qif)\n",
    "\n",
    "        self.bu = bu\n",
    "        self.bi = bi\n",
    "        self.pu = pu\n",
    "        self.qi = qi\n",
    "        self.trainset = trainset\n",
    "        \n",
    "    def test(self, testset):\n",
    "        rmse = 0\n",
    "        mae = 0\n",
    "        \n",
    "        errors = [r - self.estimate(u, i) for u, i, r in testset]\n",
    "        rmse = np.sqrt(np.mean([error**2 for error in errors]))\n",
    "        mae = np.mean([abs(error) for error in errors])\n",
    "        \n",
    "        return (rmse, mae)\n",
    "        \n",
    "        \n",
    "    def estimate(self, raw_u, raw_i):\n",
    "\n",
    "        known_user = raw_u in self.trainset._raw2inner_id_users\n",
    "        known_item = raw_i in self.trainset._raw2inner_id_items\n",
    "        \n",
    "        est = self.trainset.global_mean\n",
    "\n",
    "        if known_user:\n",
    "            u = self.trainset.to_inner_uid(raw_u)\n",
    "            est += self.bu[u]\n",
    "\n",
    "        if known_item:\n",
    "            i = self.trainset.to_inner_iid(raw_i)\n",
    "            est += self.bi[i]\n",
    "\n",
    "        if known_user and known_item:\n",
    "            est += np.dot(self.qi[i], self.pu[u])\n",
    "        \n",
    "        # clip estimation to scale of ratings\n",
    "        est = min(4, est)\n",
    "        est = max(0, est)\n",
    "\n",
    "        return est"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialization of SVD class and cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from surprise.model_selection import KFold\n",
    "\n",
    "algo = SVD(n_factors=n_factors, \n",
    "           n_epochs=n_epochs, \n",
    "           init_mean=init_mean, \n",
    "           init_std_dev=init_std_dev, \n",
    "           lr=lr, \n",
    "           reg=reg, \n",
    "           verbose=verbose)\n",
    "\n",
    "# define a cross-validation iterator\n",
    "kf = KFold(n_splits=n_splits)\n",
    "\n",
    "rmse = np.zeros(n_splits)\n",
    "mae = np.zeros(n_splits)\n",
    "fit_time = np.zeros(n_splits)\n",
    "test_time = np.zeros(n_splits)\n",
    "i = 0\n",
    "\n",
    "for trainset, testset in kf.split(data):\n",
    "    # train and test algorithm.\n",
    "    start_time = time.time()\n",
    "    algo.fit(trainset)\n",
    "    fit_time[i] = time.time()-start_time\n",
    "    \n",
    "    start_time = time.time()\n",
    "    rmse[i], mae[i] = algo.test(testset)\n",
    "    test_time[i] = time.time()-start_time\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.5070  0.5104  0.5095  0.5109  0.5119  0.5099  0.0017  \n",
      "MAE (testset)     0.2933  0.2946  0.2946  0.2934  0.2953  0.2942  0.0008  \n",
      "Fit time          18.8010 18.6230 17.7710 21.2860 21.4920 19.5946 1.5073  \n",
      "Test time         0.6800  0.6000  0.6100  0.7100  0.6400  0.6480  0.0417  \n"
     ]
    }
   ],
   "source": [
    "from six import iteritems\n",
    "\n",
    "print('Evaluating RMSE, MAE of algorithm SVD on {0} split(s).'.format(n_splits))\n",
    "print()\n",
    "row_format = '{:<18}' + '{:<8}' * (n_splits + 2)\n",
    "s = row_format.format('', *['Fold {0}'.format(i + 1) for i in range(n_splits)]\n",
    "                      + ['Mean'] + ['Std'])\n",
    "s += '\\n'\n",
    "s += row_format.format('RMSE (testset)',*['{:1.4f}'.format(vals) for vals in rmse] \n",
    "                       + ['{:1.4f}'.format(np.mean(rmse))] \n",
    "                       + ['{:1.4f}'.format(np.std(rmse))])\n",
    "s += '\\n'\n",
    "s += row_format.format('MAE (testset)',*['{:1.4f}'.format(vals) for vals in mae] \n",
    "                       + ['{:1.4f}'.format(np.mean(mae))] \n",
    "                       + ['{:1.4f}'.format(np.std(mae))])\n",
    "s += '\\n'\n",
    "s += row_format.format('Fit time',*['{:1.4f}'.format(vals) for vals in fit_time] \n",
    "                       + ['{:1.4f}'.format(np.mean(fit_time))] \n",
    "                       + ['{:1.4f}'.format(np.std(fit_time))])\n",
    "s += '\\n'\n",
    "s += row_format.format('Test time',*['{:1.4f}'.format(vals) for vals in test_time] \n",
    "                       + ['{:1.4f}'.format(np.mean(test_time))] \n",
    "                       + ['{:1.4f}'.format(np.std(test_time))])\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit model with full dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_all = data.build_full_trainset()\n",
    "algo.fit(trainset_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read qualifying set and predict all ratings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read qualifying set\n",
    "Xq = np.genfromtxt(\"qualifying.csv\", delimiter=\",\", dtype=np.int)\n",
    "\n",
    "# create array to store predictions\n",
    "predValues = np.chararray([Xq.shape[0],3], itemsize=10)\n",
    "\n",
    "# predict ratings for each element in our qualifying set\n",
    "for index, [user, item] in enumerate(Xq):\n",
    "    \n",
    "    pred = algo.estimate(str(user), str(item))\n",
    "    \n",
    "    # near-integer roundoff\n",
    "    if (np.abs( pred - np.rint( pred )) <= 0.1):\n",
    "        pred = np.rint(pred)\n",
    "    else:\n",
    "        pred = pred\n",
    "        \n",
    "    predValues[index] = [user, item, str(pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save predictions to a csv file\n",
    "import csv\n",
    "with open('qualifying_preds.csv', 'w') as f:\n",
    "   writer = csv.writer(f)\n",
    "   writer.writerows(predValues.decode('utf'))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
